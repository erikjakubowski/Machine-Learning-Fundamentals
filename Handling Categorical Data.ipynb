{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikjakubowski/Library/Python/3.6/lib/python/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature with nominal classes\n",
    "feature_labeler = np.array([[\"word\"],\n",
    "                           [\"second\"],\n",
    "                           [\"word\"],\n",
    "                           [\"third\"],\n",
    "                           [\"word\"]])\n",
    "labeler = preprocessing.LabelBinarizer()\n",
    "labeler.fit_transform(feature_labeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second</th>\n",
       "      <th>third</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   second  third  word\n",
       "0       0      0     1\n",
       "1       1      0     0\n",
       "2       0      0     1\n",
       "3       0      1     0\n",
       "4       0      0     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output the classes\n",
    "labeler.classes_\n",
    "\n",
    "#output all \n",
    "labeler.inverse_transform(labeler.transform(feature_labeler))\n",
    "\n",
    "#pandas.core.frame.DataFrame\n",
    "pd.get_dummies(feature_labeler[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi class features\n",
    "\n",
    "feature_multi = np.array([[\"Chemistry\", \"Bio-Chem\"],\n",
    "                         [\"Physics\", \"Astro-Physics\"],\n",
    "                         [\"Chemistry\", \"Bio-Chem\"],\n",
    "                         [\"Biology\", \"Bio-Chem\"],\n",
    "                         [\"Chemistry\", \"Electrochemistry\"]])\n",
    "\n",
    "labeler_multi = preprocessing.MultiLabelBinarizer()\n",
    "\n",
    "labeler_multi.fit_transform(feature_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Astro-Physics', 'Bio-Chem', 'Biology', 'Chemistry',\n",
       "       'Electrochemistry', 'Physics'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeler_multi.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn scaling text based features into numerical data\n",
    "\n",
    "txt_df = pd.DataFrame({\"Score\":[\"Low\",\"Low\",\"Medium\",\"Medium\",\"High\"]})\n",
    "\n",
    "scale_text_to_num = {\"Low\":1,\n",
    "                    \"Medium\":2,\n",
    "                    \"High\":3}\n",
    "\n",
    "num_series = txt_df[\"Score\"].replace(scale_text_to_num)\n",
    "type(num_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 7., 5.],\n",
       "       [0., 2., 0., 3.],\n",
       "       [2., 0., 0., 1.],\n",
       "       [0., 0., 1., 2.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary converted it into feature matrix\n",
    "\n",
    "data_dict = ({\"logic\": 5, \"gate\": 7},\n",
    "            {\"logic\": 3, \"XOR\": 2},\n",
    "            {\"logic\": 1, \"AND\": 2},\n",
    "            {\"logic\": 2, \"gate\": 1})\n",
    "\n",
    "dictvectorizer = feature_extraction.DictVectorizer(sparse=False)\n",
    "\n",
    "features_dict = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AND', 'XOR', 'gate', 'logic']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get feature names. Alpha order\n",
    "names = dictvectorizer.get_feature_names()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AND</th>\n",
       "      <th>XOR</th>\n",
       "      <th>gate</th>\n",
       "      <th>logic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AND  XOR  gate  logic\n",
       "0  0.0  0.0   7.0    5.0\n",
       "1  0.0  2.0   0.0    3.0\n",
       "2  2.0  0.0   0.0    1.0\n",
       "3  0.0  0.0   1.0    2.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df = pd.DataFrame(features_dict, columns=names)\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  2.87,  3.31],\n",
       "       [ 1.  ,  0.67, -0.22],\n",
       "       [ 0.  ,  3.1 ,  2.45],\n",
       "       [ 1.  ,  0.18,  0.33],\n",
       "       [ 0.  ,  2.22,  3.27],\n",
       "       [ 1.  , -0.21, -0.19]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorical feature containing missing values, and replace it with predicted values.\n",
    "\n",
    "X = np.array([[0, 3.10, 2.45],\n",
    "              [1, .18, .33],\n",
    "              [0, 2.22, 3.27],\n",
    "              [1, -.21, -.19]])\n",
    "\n",
    "#create a 0 and a 1\n",
    "X_with_nan = np.array([[np.nan, 2.87, 3.31],\n",
    "                       [np.nan, 0.67, -0.22]])\n",
    "\n",
    "#possibe weight uniform, distance, or \"callable\" user defined function\n",
    "clf_kn = neighbors.KNeighborsClassifier(3, weights='distance')\n",
    "\n",
    "trained_kn_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "imputed_values = trained_kn_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  2.87,  3.31],\n",
       "       [ 0.  ,  0.67, -0.22],\n",
       "       [ 0.  ,  3.1 ,  2.45],\n",
       "       [ 1.  ,  0.18,  0.33],\n",
       "       [ 0.  ,  2.22,  3.27],\n",
       "       [ 1.  , -0.21, -0.19]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alt solution is to just fill with most frequest feature value on axis\n",
    "#Join matricies\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = preprocessing.Imputer(strategy='most_frequent', axis=0)\n",
    "\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imbalanced classes\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "features_iris = iris.data\n",
    "\n",
    "targets_iris = iris.target\n",
    "\n",
    "feature_set = features_iris[40:,:]\n",
    "target_set = targets_iris[40:]\n",
    "\n",
    "target_where = np.where((target_set == 0),0,1)\n",
    "target_where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0: 0.9, 1: 0.1},\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create weights\n",
    "\n",
    "weights = {0:.9,1:0.1}\n",
    "ensemble.RandomForestClassifier(class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class0 = np.where(target_where == 0)[0]\n",
    "i_class1 = np.where(target_where == 1)[0]\n",
    "\n",
    "length_class0 = len(i_class0)\n",
    "length_class1 = len(i_class1)\n",
    "\n",
    "#downsampling\n",
    "i_class1_downsample = np.random.choice(i_class1, size=length_class0, replace=False)\n",
    "\n",
    "#vector\n",
    "np.hstack((target_where[i_class0], target_where[i_class1_downsample]))\n",
    "\n",
    "#matrix\n",
    "np.vstack((features_iris[i_class0,:], features_iris[i_class1_downsample,:]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_class0_upsampled = np.random.choice(i_class0, size=length_class1, replace=True)\n",
    "\n",
    "#vector\n",
    "np.concatenate((target_where[i_class0_upsampled], target_where[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9, 3. , 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.4, 3.9, 1.7, 0.4]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix\n",
    "np.vstack((features_iris[i_class0_upsampled,:], features_iris[i_class1,:]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
