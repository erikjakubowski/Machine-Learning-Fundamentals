{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling\n",
    "standardizing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [500.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. ],\n",
       "       [0.4],\n",
       "       [0.5],\n",
       "       [0.6],\n",
       "       [1. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale from 0 to 1, sometimes -1 to 1, and giving each array index a location_value based on its distance from the max-min range \n",
    "#x′i=xi−min(x)max(x)−min(x)\n",
    "\n",
    "minimun_scale = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "scaled_feature = minimun_scale.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# You want to transform a feature to have a mean of 0 and a standard deviation of 1.\n",
    "x_std_sc = np.array([[-10111.1],\n",
    "              [-310.2],\n",
    "              [450.5],\n",
    "              [610.6],\n",
    "              [9090.9]])\n",
    "\n",
    "scaler_std_sc = preprocessing.StandardScaler()\n",
    "\n",
    "standardized_std_sc = scaler_std_sc.fit_transform(x_std_sc)\n",
    "\n",
    "standardized_std_sc\n",
    "\n",
    "print(int(standardized_std_sc.mean()))\n",
    "print(int(standardized_std_sc.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.47002606],\n",
       "       [ -0.82612945],\n",
       "       [  0.        ],\n",
       "       [  0.17387055],\n",
       "       [  9.3835795 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if data has significant outliers, we can use use a robust scaler to use median and quartile range instead\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "robust_scaler.fit_transform(x_std_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.6       ],\n",
       "       [0.21428571, 0.78571429],\n",
       "       [0.07017544, 0.92982456],\n",
       "       [0.04103672, 0.95896328],\n",
       "       [0.99224806, 0.00775194]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You want to rescale the feature values of observations to have unit norm or a total length of 1 on indiviual \n",
    "#obvservations not just entire feature\n",
    "features_norm = np.array([[0.4,0.6],\n",
    "                         [1.2, 4.4],\n",
    "                         [1.6,21.2],\n",
    "                         [1.9, 44.4],\n",
    "                         [12.8, 0.1]])\n",
    "\n",
    "#Eucliean by default norm = 12\n",
    "normalizer = preprocessing.Normalizer()\n",
    "\n",
    "normalizer.transform(features_norm)\n",
    "\n",
    "#Manhattan version\n",
    "normalizer_man = preprocessing.Normalizer(norm='l1')\n",
    "\n",
    "normalizer_man.transform(features_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  6., 16., 24., 36.],\n",
       "       [ 1.,  3.,  7.,  9., 21., 49.],\n",
       "       [ 1.,  1.,  2.,  1.,  2.,  4.],\n",
       "       [ 1.,  1.,  5.,  1.,  5., 25.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create polynominal and interaction features.\n",
    "#If an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
    "feature_poly = np.array([[4,6],\n",
    "                        [3,7],\n",
    "                         [1,2],\n",
    "                        [1,5]])\n",
    "\n",
    "scaler_poly = preprocessing.PolynomialFeatures(2)\n",
    "\n",
    "scaler_poly.fit_transform(feature_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4,  -3],\n",
       "       [ -2,   2],\n",
       "       [  5,   6],\n",
       "       [ 95, 145]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You want to make a custom transformation to one or more features\n",
    "feature_tran = np.array([[1,2],\n",
    "                        [3,7],\n",
    "                        [10,11],\n",
    "                        [100,150]])\n",
    "\n",
    "def add_negative(arr):\n",
    "    return arr + -5\n",
    "\n",
    "neg_transformer = preprocessing.FunctionTransformer(add_negative)\n",
    "\n",
    "neg_transformer.transform(feature_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You have a numerical feature and want to break it up into discrete bins \n",
    "#Binarizer(value) value is cut off for bins also / digitize for mulitple bins\n",
    "bin_nums = np.array([[1],\n",
    "                    [12],\n",
    "                    [34],\n",
    "                    [1000],\n",
    "                    [20345]])\n",
    "binarizer = preprocessing.Binarizer(40)\n",
    "\n",
    "binarizer.fit_transform(bin_nums)\n",
    "\n",
    "np.digitize(bin_nums, bins=[13,1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      0\n",
       "1  -7.287210  -8.353986      2\n",
       "2  -6.943061  -7.023744      2\n",
       "3  -7.440167  -8.791959      2\n",
       "4  -6.641388  -8.075888      2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You want to cluster observations so that similar observations are grouped together\n",
    "\n",
    "features_cl, _ = make_blobs(n_samples=50,\n",
    "                        n_features=2,\n",
    "                        centers=3,\n",
    "                        random_state=1)\n",
    "\n",
    "cluster_df = pd.DataFrame(features_cl, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "cluster = KMeans(3, random_state=0)\n",
    "cluster.fit(features_cl)\n",
    "cluster_df[\"group\"] = cluster.predict(features_cl)\n",
    "cluster_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You need to delete observations containing missing values\n",
    "features_nan = np.array([[1.1, 11.1],\n",
    "                     [2.2, 22.2],\n",
    "                     [3.3, 33.3],\n",
    "                     [4.4, 44.4],\n",
    "                     [np.nan, 55]])\n",
    "\n",
    "features_nan[~np.isnan(features_nan).any(axis=1)]\n",
    "\n",
    "#or\n",
    "nan_df = pd.DataFrame(features_nan, columns=[\"feature_1\", \"feature_2\"])\n",
    "nan_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You have missing values in your data and want to fill in or predict their values\n",
    "\n",
    "# feature_miss, _ = make_blobs(n_samples=1000, n_features=2, random_state=1)\n",
    "# scaler_miss = preprocessing.StandardScaler()\n",
    "# stand_features_miss = scaler_miss.fit_transform(feature_miss)\n",
    "# true_value = stand_features_miss[0,0]\n",
    "# stand_features_miss[0,0] = np.nan\n",
    "\n",
    "# feature_knn_in = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
