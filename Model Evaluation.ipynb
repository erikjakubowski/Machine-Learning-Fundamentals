{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are only as useful as the quality of their predictions, and thus fundamentally our goal is not to create models (which is easy) but to create high-quality models (which is hard). Therefore, before we explore the myriad learning algorithms, we first set up how we can evaluate the models they produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline that preprocesses the data, trains the model, and then evaluates it using cross-validation\n",
    "\n",
    "iris_digits = datasets.load_digits()\n",
    "iris_features = iris_digits.data\n",
    "iris_target = iris_digits.target\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "boston_features, boston_targets = boston.data,boston.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "logit = LogisticRegression()\n",
    "\n",
    "pipeline = make_pipeline(standardizer, logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964931719428926"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "cv_results = cross_val_score(pipeline, iris_features, iris_target, cv=kf, scoring=\"accuracy\", n_jobs=1)\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two examples of DummyBaseline models. \n",
    "Regressiona and Classification. \n",
    "And compare the scores to LinearRegression() and RandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6353620786674619"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create baseline REGRESSION model\n",
    "#You want a simple baseline regression model to compare against your model\n",
    "#his regressor is useful as a simple baseline to compare with other (real) regressors. Don't use for real problems\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    boston_features, boston_targets, random_state=0)\n",
    "\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "dummy.score(features_test, target_test)\n",
    "\n",
    "\n",
    "# # Create dummy regressor that predicts 20's for everything\n",
    "# clf = DummyRegressor(strategy='constant', constant=20)\n",
    "# clf.fit(features_train, target_train)\n",
    "\n",
    "# # Evaluate score\n",
    "# clf.score(features_test, target_test)\n",
    "\n",
    "#Non-dummy model\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You want a simple baseline CLASSIFIER to compare against your model\n",
    "# Load flower data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, random_state=0)\n",
    "\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy.score(features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Actual Classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Train model\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classification model.\n",
    "True Positives and True Negatives with False Positive and False Negatives (TP,TN,FP,FN) \n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95166617, 0.95765275, 0.95558223])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples = 10000,\n",
    "                           n_features = 3,\n",
    "                           n_informative = 3,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           random_state = 1)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "cross_val_score(logit,X,y, scoring=\"accuracy\")\n",
    "\n",
    "#Precision is the proportion of every observation predicted to be positive that is actually positive. \n",
    "#We can think about it as a measurement noise in our predictions—that is, when we predict something is positive, how likely we are to be right. \n",
    "#Models with high precision are pessimistic in that they only predict an observation is of the positive class when they are very certain about it.\n",
    "# P = TP/(TP+FP)\n",
    "cross_val_score(logit,X,y, scoring=\"precision\")\n",
    "\n",
    "#Recall is the proportion of every positive observation that is truly positive. Recall measures the model’s ability to identify an observation of the positive class. \n",
    "#Models with high recall are optimistic in that they have a low bar for predicting that an observation is in the positive class\n",
    "# R = TP/(TP/FN)\n",
    "cross_val_score(logit,X,y, scoring=\"recall\")\n",
    "\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "cross_val_score(logit,X,y, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You want to evaluate a binary classifier and various probability thresholds\n",
    "roc_feature, roc_target = make_classification(n_samples=5000,\n",
    "                                             n_features=5,\n",
    "                                             n_classes=2,\n",
    "                                             n_informative=3,\n",
    "                                             random_state=3)\n",
    "roc_features_train, roc_features_test, roc_target_train, roc_target_test = train_test_split(roc_feature, roc_target,\n",
    "                                                                                           test_size=0.1, random_state=1)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(roc_features_train, roc_target_train)\n",
    "\n",
    "roc_target_probability = logit.predict_proba(roc_features_test)[:,1]\n",
    "\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(roc_target_test,\n",
    "                                                               roc_target_probability)\n",
    "\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.9686408 , -2.09841386, -1.96596986, -1.40162674,  1.22208429]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view predicted probabilities\n",
    "roc_features_test[0:1]\n",
    "# logit.predict_proba(roc_features_test)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.64523025, -0.46164841, -1.38822831,  0.17903566, -0.94450214]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_features_train[0:1]\n",
    "# logit.predict_proba(roc_features_train)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
